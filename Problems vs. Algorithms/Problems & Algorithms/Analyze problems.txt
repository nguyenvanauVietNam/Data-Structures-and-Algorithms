"""
Problem 1: Square Root of an Integer

Find the square root of the integer without using any Python library. You have to find the floor value of the square root.
For example if the given number is 16, then the answer would be 4.
If the given number is 27, the answer would be 5 because sqrt(5) = 5.196 whose floor value is 5.
The expected time complexity is O(log(n))

Ananlysis:
The above code implements the algorithm to find the square root of a positive integer number using the binary search method.
Let's analyze each line of code to understand how the algorithm works and its complexity:

1.	if number == 0 or number == 1:
	a.	Check if number is 0 or 1.
	b.	This is a basic case where if number is 0 or 1, the square root of it is number.
	c.	Complexity: O(1), as it only requires one check of number.
2.	left, right = 1, number
	a.	Initialize two variables, left and right, where in this case, left is set to 1 and right is set to number.
	b.	left and right are two indices within the binary search range to determine the square root.
	c.	Complexity: O(1).
3.	result = 0
	a.	Initialize the result variable to store a temporary result.
	b.	Initially, result is set to 0.
	c.	Complexity: O(1).
4.	while left <= right:
	a.	Start a while loop with the condition that left should not exceed right.
	b.	This loop continues until left becomes greater than right, which means the square root has been found or cannot be found.
5.	mid = (left + right) // 2
	a.	Calculate the average value mid between left and right.
	b.	This is a crucial step in the binary search algorithm.
	c.	Complexity: O(1).
6.	if mid * mid == number:
	a.	Check if the square of mid is equal to number.
	b.	If so, mid is the square root of number, and we return mid.
	c.	Complexity: O(1).
7.	elif mid * mid < number:
	a.	If the square of mid is less than number, we update left = mid + 1 and store the value of mid in result as a temporary result.
	b.	This is a step of advancing within the search range.
	c.	Complexity: O(1).
8.	else:
	a.	In the remaining case, where the square of mid is greater than number, we update right = mid - 1 to narrow down the search range.
	b.	Complexity: O(1).
9.	Finally, after the loop is finished, we return result as the nearest square root of number.
	a.	Complexity: O(1).
10.	In summary, the complexity of this square root finding algorithm is O(log(n)), where n is the value of number.
The search range is halved in each step until we find the result or determine it's not possible.
"""

"""
Problem 2: Search in a Rotated Sorted Array

You are given a sorted array which is rotated at some random pivot point.
Example: [0,1,2,4,5,6,7] might become [4,5,6,7,0,1,2]
You are given a target value to search. If found in the array return its index, otherwise return -1.
You can assume there are no duplicates in the array and your algorithm's runtime complexity must be in the order of O(log n).

Ananlysis:
To analyze the complexity of the rotated_array_search algorithm, we will examine each part of the code and consider the time and space complexity of each part:
	1.	Initializing left and right variables: This only takes a constant number of steps, as it involves assigning the initial values to the beginning and end of the array.
	Therefore, the time complexity is O(1), and the space complexity is O(1).
	2.	The while loop: This loop continues to run until left is no longer less than or equal to right. In each iteration, the algorithm performs a fixed number of operations, including calculating the middle value mid and several comparisons and assignments.
	Therefore, the time complexity of this loop is O(log n), where "n" is the length of the input_list.
	3.	Within each loop iteration, there are a number of comparisons and assignments to check and update left and right.
	However, the total number of comparisons and assignments within the loop does not exceed a constant and is dependent on the size of the array. Thus, the time complexity is O(log n).
In summary, the time complexity of the rotated_array_search algorithm is O(log n), where "n" is the length of the input_list. The space complexity is O(1) because the algorithm does not use additional memory in proportion to the input data size.
Comparing it to the linear_search algorithm you provided, the rotated_array_search algorithm has a better time complexity (O(log n) compared to O(n) of the linear search algorithm).

"""

"""
Problem 3: Rearrange Array Digits
Rearrange Array Elements so as to form two number such that their sum is maximum. Return these two numbers. You can assume that all array elements are in the range [0, 9]. The number of digits in both the numbers cannot differ by more than 1. You're not allowed to use any sorting function that Python provides and the expected time complexity is O(nlog(n)).
for e.g. [1, 2, 3, 4, 5]
The expected answer would be [531, 42]. Another expected answer can be [542, 31]. In scenarios such as these when there are more than one possible answers, return any one.

Ananlysis:
The provided Python algorithm is a function named rearrange_digits that takes a list of digits as input and rearranges them to form two numbers in such a way that the two resulting numbers have the maximum and second maximum possible values. Here's the English explanation and analysis of the algorithm's complexity:
1.	Input Validation:
	•	The function first checks if the input list has a length less than or equal to 1. If so, it returns the input list itself, as no rearrangement is required.
2.	Merge Sort:
	•	The algorithm uses the merge sort algorithm to sort the input list. Merge sort is a divide-and-conquer algorithm that recursively divides the list into smaller sublists and then merges them back together in a sorted manner.
	•	The time complexity of merge sort is O(n log n), where n is the number of elements in the input list.
3.	Merging Two Sorted Lists:
	•	The merge function merges two sorted lists into a single sorted list. The time complexity of this operation is O(n), where n is the combined size of the two input lists.
4.	Splitting and Merging:
	•	The merge_sort function recursively splits the input list into smaller halves and sorts them using the merge function. This process continues until the base case is reached (a list with 1 or 0 elements).
5.	Reconstruction of Numbers:
	•	After sorting the input list, the algorithm constructs two numbers (num1 and num2) by iteratively picking digits from the sorted list. Digits at even indices form num1, and digits at odd indices form num2.
	•	This step takes O(n) time because it iterates through the sorted list once.
Overall, the time complexity of the rearrange_digits function is dominated by the merge sort step, which is O(n log n), where n is the number of elements in the input list. The rest of the operations are either constant time or linear in the size of the input list and do not significantly impact the overall complexity.

"""

"""
Problem 4: Dutch National Flag Problem
Given an input array consisting on only 0, 1, and 2, sort the array in a single traversal.
You're not allowed to use any sorting function that Python provides.
Note: O(n) does not necessarily mean single-traversal.
For e.g. if you traverse the array twice, that would still be an O(n) solution but it will not count as single traversal.

Ananlysis:
This algorithm is known as the "Dutch National Flag" algorithm, and it's used to sort an array containing only the elements 0, 1, and 2. Here's the analysis of its time complexity in English:
1.	Initialize three pointers (low, mid, and high): These operations take constant time, O(1).
2.	While loop: The while loop iterates through the elements of the input list once. In the worst case, it needs to go through all the elements in the list, which takes O(n) time, where n is the length of the input list.
3.	Inside the while loop:
	•	Swapping elements: The swapping operations (input_list[low], input_list[mid] = input_list[mid], input_list[low] and input_list[mid], input_list[high] = input_list[high], input_list[mid]) take constant time, O(1), for each swap.
	•	Incrementing pointers: Incrementing the low and mid pointers and decrementing the high pointer is done in constant time, O(1), for each operation.
4.	The overall time complexity of the algorithm is O(n) in the worst case, where n is the length of the input list. This is because the algorithm processes each element in the input list once.
So, the time complexity of this "sort_012" algorithm is O(n), making it a linear time algorithm.

"""


"""
Problem 5: Autocomplete with Tries

Ananlysis:
The provided code defines a Trie data structure for storing and searching words. Here's a complexity analysis of the code:
1.	TrieNode Class:
	•	The TrieNode class represents a single node in the Trie.
	•	The __init__ method initializes the node with an empty dictionary to store children nodes and a boolean variable to mark the end of a word.
	•	The insert method inserts a character as a child node in the Trie, creating a new TrieNode object if the character does not already exist in the children dictionary.
	•	Both the __init__ and insert methods have constant time complexity, O(1), because they involve simple dictionary operations and attribute assignments.
2.	Trie Class:
	•	The Trie class represents the Trie data structure and is composed of TrieNode objects.
	•	The __init__ method initializes the Trie with a root node.
	•	The insert method inserts a word into the Trie, iterating through each character of the word and inserting them one by one into the Trie. This method has a time complexity of O(m), where 'm' is the length of the word being inserted.
	•	The find method finds the Trie node that represents a given prefix by following the path in the Trie. The time complexity of this method is O(n), where 'n' is the length of the prefix.
3.	suffixes Method:
	•	The suffixes method is a recursive function that collects all suffixes for complete words below a given node in the Trie.
	•	It iterates through the children of the current node and appends suffixes to a list whenever it reaches the end of a word.
	•	The time complexity of this method depends on the number of nodes and complete words in the Trie. In the worst case, where there are 'k' complete words and 'n' nodes in the Trie, the time complexity is O(n + k).
In summary, the code's time complexity can be analyzed as follows:
	•	Inserting a word into the Trie: O(m), where 'm' is the length of the word.
	•	Finding a prefix in the Trie: O(n), where 'n' is the length of the prefix.
	•	Collecting suffixes for complete words: O(n + k), where 'n' is the number of nodes and 'k' is the number of complete words in the Trie.

"""

"""
Problem 6: Unsorted Integer Array
Max and Min in a Unsorted Array
In this problem, we will look for smallest and largest integer from a list of unsorted integers. The code should run in O(n) time. Do not use Python's inbuilt functions to find min and max.

Bonus Challenge: Is it possible to find the max and min in a single traversal?
Ananlysis:

The given algorithm finds the minimum and maximum values in a list of integers. Here's the analysis of its time complexity in English:
1.	The algorithm starts by checking if the input list, ints, is empty. If it is empty, the function returns None. This step takes constant time, O(1), as it involves a single if statement.
2.	If the input list is not empty, the algorithm initializes two variables, min_val and max_val, to the first element of the list. This initialization step is also constant time, O(1).
3.	Next, the algorithm iterates through each element in the input list, ints, and updates min_val and max_val accordingly. This loop runs for each element in the list, resulting in a linear time complexity, O(n), where 'n' is the number of elements in the input list.
4.	Finally, the algorithm returns a tuple containing the minimum and maximum values found, which is a constant-time operation, O(1).
The overall time complexity of this algorithm is O(n) because the loop is the dominant factor, and it iterates through the list once to find the minimum and maximum values.

"""

roblem 7: Request Routing in a Web Server with a Trie
HTTPRouter using a Trie
For this exercise we are going to implement an HTTPRouter like you would find in a typical web server using the Trie data structure we learned previously.

There are many different implementations of HTTP Routers such as regular expressions or simple string matching, but the Trie is an excellent and very efficient data structure for this purpose.

The purpose of an HTTP Router is to take a URL path like "/", "/about", or "/blog/2019-01-15/my-awesome-blog-post" and figure out what content to return. In a dynamic web server, the content will often come from a block of code called a handler.

First we need to implement a slightly different Trie than the one we used for autocomplete. Instead of simple words the Trie will contain a part of the http path at each node, building from the root node /

In addition to a path though, we need to know which function will handle the http request. In a real router we would probably pass an instance of a class like Python's SimpleHTTPRequestHandler which would be responsible for handling requests to that path. For the sake of simplicity we will just use a string that we can print out to ensure we got the right handler

We could split the path into letters similar to how we did the autocomplete Trie, but this would result in a Trie with a very large number of nodes and lengthy traversals if we have a lot of pages on our site. A more sensible way to split things would be on the parts of the path that are separated by slashes ("/"). A Trie with a single path entry of: "/about/me" would look like:

(root, None) -> ("about", None) -> ("me", "About Me handler")

We can also simplify our RouteTrie a bit by excluding the suffixes method and the endOfWord property on RouteTrieNodes. We really just need to insert and find nodes, and if a RouteTrieNode is not a leaf node, it won't have a handler which is fine.


Ananlysis:
Analyze the complexity of the algorithm in the provided code:
1.	RouteTrie:
	•	__init__: This method has a time complexity of O(1) because it only creates a RouteTrieNode object and assigns it to the root node.
	•	insert: This method has a time complexity of O(n), where n is the length of the path. During insertion, we have to iterate through each element in the path and create child nodes if they don't exist.
	•	find: This method also has a time complexity of O(n) because we have to traverse through each element in the path to search on the Trie tree.
	•	split_path: This method has a time complexity of O(n) as well because it needs to split the path into individual components.
2.	RouteTrieNode:
	•	__init__: This method has a time complexity of O(1) because it only initializes an empty dictionary and a handler.
3.	Router:
	•	__init__: This method has a time complexity of O(1) because it only creates a RouteTrie object and assigns it to the root of the Trie tree. The complexity also depends on initializing the not_found_handler, but this doesn't significantly increase the complexity.
	•	add_handler: This method has a time complexity of O(n), similar to the insert method in RouteTrie.
	•	lookup: This method has a time complexity of O(n), similar to the find method in RouteTrie.
	•	split_path: This method has a time complexity of O(n), similar to the split_path method in RouteTrie.
In summary, the complexity of the system depends on the length of the path (n) and the number of elements in the Trie tree that have been added. The search time is O(n), where n is the length of the path. If there are N paths added, the worst-case search complexity is O(N).

"""
